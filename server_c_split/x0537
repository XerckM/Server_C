  auVar18 = vpslld_avx2(auVar19,2);
  auVar19 = vpsrld_avx2(auVar19,0x1e);
  auVar19 = vpor_avx2(auVar18,auVar19);
  auVar18 = vpaddd_avx2(auVar19,K_XMM_AR._64_32_);
  local_3e8 = vmovdqu_avx(auVar18);
  auVar18 = vpalignr_avx2(auVar19,auVar21,8);
  auVar22 = vpxor_avx2(auVar22,auVar20);
  auVar18 = vpxor_avx2(auVar18,auVar26);
  auVar22 = vpxor_avx2(auVar22,auVar18);
  auVar18 = vpslld_avx2(auVar22,2);
  auVar22 = vpsrld_avx2(auVar22,0x1e);
  auVar22 = vpor_avx2(auVar18,auVar22);
  auVar18 = vpaddd_avx2(auVar22,K_XMM_AR._64_32_);
  local_3c8 = vmovdqu_avx(auVar18);
  auVar18 = vpalignr_avx2(auVar22,auVar19,8);
  auVar20 = vpxor_avx2(auVar20,auVar28);
  auVar18 = vpxor_avx2(auVar18,auVar23);
  auVar20 = vpxor_avx2(auVar20,auVar18);
  auVar18 = vpslld_avx2(auVar20,2);
  auVar20 = vpsrld_avx2(auVar20,0x1e);
  auVar20 = vpor_avx2(auVar18,auVar20);
  auVar18 = vpaddd_avx2(auVar20,K_XMM_AR._96_32_);
  local_3a8 = vmovdqu_avx(auVar18);
  auVar18 = vpalignr_avx2(auVar20,auVar22,8);
  auVar25 = vpxor_avx2(auVar28,auVar27);
  auVar18 = vpxor_avx2(auVar18,auVar21);
  auVar25 = vpxor_avx2(auVar25,auVar18);
  auVar18 = vpslld_avx2(auVar25,2);
  auVar25 = vpsrld_avx2(auVar25,0x1e);
  auVar28 = vpor_avx2(auVar18,auVar25);
  auVar18 = vpaddd_avx2(auVar28,K_XMM_AR._96_32_);
  local_388 = vmovdqu_avx(auVar18);
  auVar18 = vpalignr_avx2(auVar28,auVar20,8);
  auVar25 = vpxor_avx2(auVar27,auVar26);
  auVar18 = vpxor_avx2(auVar18,auVar19);
  auVar19 = vpxor_avx2(auVar25,auVar18);
  auVar18 = vpslld_avx2(auVar19,2);
  auVar19 = vpsrld_avx2(auVar19,0x1e);
  auVar25 = vpor_avx2(auVar18,auVar19);
  auVar18 = vpaddd_avx2(auVar25,K_XMM_AR._96_32_);
  local_368 = vmovdqu_avx(auVar18);
  auVar18 = vpalignr_avx2(auVar25,auVar28,8);
  auVar19 = vpxor_avx2(auVar26,auVar23);
  auVar18 = vpxor_avx2(auVar18,auVar22);
  auVar22 = vpxor_avx2(auVar19,auVar18);
  auVar18 = vpslld_avx2(auVar22,2);
  auVar22 = vpsrld_avx2(auVar22,0x1e);
  auVar22 = vpor_avx2(auVar18,auVar22);
  auVar18 = vpaddd_avx2(auVar22,K_XMM_AR._96_32_);
  local_348 = vmovdqu_avx(auVar18);
  auVar18 = vpalignr_avx2(auVar22,auVar25,8);
  auVar22 = vpxor_avx2(auVar23,auVar21);
  auVar18 = vpxor_avx2(auVar18,auVar20);
  auVar20 = vpxor_avx2(auVar22,auVar18);
  auVar18 = vpslld_avx2(auVar20,2);
  auVar20 = vpsrld_avx2(auVar20,0x1e);
  auVar18 = vpor_avx2(auVar18,auVar20);
  auVar18 = vpaddd_avx2(auVar18,K_XMM_AR._96_32_);
  local_328 = vmovdqu_avx(auVar18);
  pauVar3 = (undefined (*) [32])local_2e8;
  pauVar17 = &local_588;
  while (pauVar16 = pauVar3, in_stack_00000010 != K_XMM_AR) {
    dVar10 = dVar6 >> 2 | dVar6 << 0x1e;
    dVar9 = dVar4 >> 2 | dVar4 << 0x1e;
    auVar2 = vmovdqu_avx(*(undefined (*) [16])((int)in_stack_00000010 + 0x80));
    dVar6 = dVar5 + *(sdword *)*pauVar17 + (dVar6 & dVar11 ^ ~dVar6 & dVar7) +
            (dVar4 >> 0x1b | dVar4 << 5);
    dVar5 = dVar6 >> 2 | dVar6 * 0x40000000;
    auVar21._16_16_ = *(undefined (*) [16])((int)puVar15 + 0x80);
    auVar21._0_16_ = auVar2;
    dVar4 = dVar7 + *(sdword *)(*pauVar17 + 4) + (dVar4 & dVar10 ^ ~dVar4 & dVar11) +
            (dVar6 >> 0x1b | dVar6 * 0x20);
    dVar7 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar29 = vpshufb_avx2(auVar21,auVar24);
    dVar11 = dVar11 + *(sdword *)(*pauVar17 + 8) + (dVar6 & dVar9 ^ ~dVar6 & dVar10) +
             (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar6 = dVar11 >> 2 | dVar11 * 0x40000000;
    dVar4 = dVar10 + *(sdword *)(*pauVar17 + 0xc) + (dVar4 & dVar5 ^ ~dVar4 & dVar9) +
            (dVar11 >> 0x1b | dVar11 * 0x20);
    dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar18 = vpaddd_avx2(auVar29,K_XMM_AR._0_32_);
    dVar11 = dVar9 + *(sdword *)pauVar17[1] + (dVar11 & dVar7 ^ ~dVar11 & dVar5) +
             (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar10 = dVar11 >> 2 | dVar11 * 0x40000000;
    dVar4 = dVar5 + *(sdword *)(pauVar17[1] + 4) + (dVar4 & dVar6 ^ ~dVar4 & dVar7) +
            (dVar11 >> 0x1b | dVar11 * 0x20);
    dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
    dVar7 = dVar7 + *(sdword *)(pauVar17[1] + 8) + (dVar11 & dVar12 ^ ~dVar11 & dVar6) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    sVar1 = *(sdword *)(pauVar17[1] + 0xc);
    dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
    auVar18 = vmovdqu_avx(auVar18);
    *pauVar16 = auVar18;
    dVar4 = dVar6 + sVar1 + (dVar4 & dVar10 ^ ~dVar4 & dVar12) + (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar2 = vmovdqu_avx(*(undefined (*) [16])((int)in_stack_00000010 + 0x90));
    dVar7 = dVar12 + *(sdword *)pauVar17[2] + (dVar7 & dVar9 ^ ~dVar7 & dVar10) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
    auVar23._16_16_ = *(undefined (*) [16])((int)puVar15 + 0x90);
    auVar23._0_16_ = auVar2;
    dVar4 = dVar10 + *(sdword *)(pauVar17[2] + 4) + (dVar4 & dVar11 ^ ~dVar4 & dVar9) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar28 = vpshufb_avx2(auVar23,auVar24);
    dVar7 = dVar9 + *(sdword *)(pauVar17[2] + 8) + (dVar7 & dVar5 ^ ~dVar7 & dVar11) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
    dVar4 = dVar11 + *(sdword *)(pauVar17[2] + 0xc) + (dVar4 & dVar6 ^ ~dVar4 & dVar5) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar18 = vpaddd_avx2(auVar28,K_XMM_AR._0_32_);
    dVar7 = dVar5 + *(sdword *)pauVar17[3] + (dVar7 & dVar12 ^ ~dVar7 & dVar6) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
    dVar4 = dVar6 + *(sdword *)(pauVar17[3] + 4) + (dVar4 & dVar10 ^ ~dVar4 & dVar12) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
    dVar7 = dVar12 + *(sdword *)(pauVar17[3] + 8) + (dVar7 & dVar9 ^ ~dVar7 & dVar10) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    sVar1 = *(sdword *)(pauVar17[3] + 0xc);
    dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
    auVar18 = vmovdqu_avx(auVar18);
    pauVar16[1] = auVar18;
    dVar4 = dVar10 + sVar1 + (dVar4 & dVar11 ^ ~dVar4 & dVar9) + (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar2 = vmovdqu_avx(*(undefined (*) [16])((int)in_stack_00000010 + 0xa0));
    dVar7 = dVar9 + *(sdword *)pauVar17[4] + (dVar7 & dVar5 ^ ~dVar7 & dVar11) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
    auVar25._16_16_ = *(undefined (*) [16])((int)puVar15 + 0xa0);
    auVar25._0_16_ = auVar2;
    dVar4 = dVar11 + *(sdword *)(pauVar17[4] + 4) + (dVar4 & dVar6 ^ ~dVar4 & dVar5) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar27 = vpshufb_avx2(auVar25,auVar24);
    dVar7 = dVar5 + *(sdword *)(pauVar17[4] + 8) + (dVar7 & dVar12 ^ ~dVar7 & dVar6) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
    dVar4 = dVar6 + *(sdword *)(pauVar17[4] + 0xc) + (dVar4 & dVar10 ^ ~dVar4 & dVar12) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar18 = vpaddd_avx2(auVar27,K_XMM_AR._0_32_);
    dVar7 = dVar12 + *(sdword *)pauVar17[5] + (dVar7 ^ dVar9 ^ dVar10) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
    dVar4 = dVar10 + *(sdword *)(pauVar17[5] + 4) + (dVar4 ^ dVar11 ^ dVar9) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
    dVar7 = dVar9 + *(sdword *)(pauVar17[5] + 8) + (dVar7 ^ dVar5 ^ dVar11) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    sVar1 = *(sdword *)(pauVar17[5] + 0xc);
    dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
    auVar18 = vmovdqu_avx(auVar18);
    pauVar16[2] = auVar18;
    dVar4 = dVar11 + sVar1 + (dVar4 ^ dVar6 ^ dVar5) + (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar2 = vmovdqu_avx(*(undefined (*) [16])((int)in_stack_00000010 + 0xb0));
    dVar7 = dVar5 + *(sdword *)pauVar17[6] + (dVar7 ^ dVar12 ^ dVar6) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
    auVar26._16_16_ = *(undefined (*) [16])((int)puVar15 + 0xb0);
    auVar26._0_16_ = auVar2;
    dVar4 = dVar6 + *(sdword *)(pauVar17[6] + 4) + (dVar4 ^ dVar10 ^ dVar12) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar25 = vpshufb_avx2(auVar26,auVar24);
    dVar7 = dVar12 + *(sdword *)(pauVar17[6] + 8) + (dVar7 ^ dVar9 ^ dVar10) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
    dVar4 = dVar10 + *(sdword *)(pauVar17[6] + 0xc) + (dVar4 ^ dVar11 ^ dVar9) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar18 = vpaddd_avx2(auVar25,K_XMM_AR._0_32_);
    dVar7 = dVar9 + *(sdword *)pauVar17[7] + (dVar7 ^ dVar5 ^ dVar11) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
    dVar4 = dVar11 + *(sdword *)(pauVar17[7] + 4) + (dVar4 ^ dVar6 ^ dVar5) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
    dVar7 = dVar5 + *(sdword *)(pauVar17[7] + 8) + (dVar7 ^ dVar12 ^ dVar6) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    sVar1 = *(sdword *)(pauVar17[7] + 0xc);
    dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
    auVar18 = vmovdqu_avx(auVar18);
    pauVar16[3] = auVar18;
    dVar4 = dVar6 + sVar1 + (dVar4 ^ dVar10 ^ dVar12) + (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar20 = vpalignr_avx2(auVar28,auVar29,8);
    auVar18 = vpsrldq_avx2(auVar25,4);
    dVar7 = dVar12 + *(sdword *)pauVar17[8] + (dVar7 ^ dVar9 ^ dVar10) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
    auVar20 = vpxor_avx2(auVar20,auVar27);
    auVar18 = vpxor_avx2(auVar18,auVar29);
    dVar4 = dVar10 + *(sdword *)(pauVar17[8] + 4) + (dVar4 ^ dVar11 ^ dVar9) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar20 = vpxor_avx2(auVar20,auVar18);
    auVar22 = vpslldq_avx2(auVar20,0xc);
    dVar7 = dVar9 + *(sdword *)(pauVar17[8] + 8) + (dVar7 ^ dVar5 ^ dVar11) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
    auVar18 = vpslld_avx2(auVar20,1);
    auVar20 = vpsrld_avx2(auVar20,0x1f);
    dVar4 = dVar11 + *(sdword *)(pauVar17[8] + 0xc) + (dVar4 ^ dVar6 ^ dVar5) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar18 = vpor_avx2(auVar18,auVar20);
    auVar20 = vpslld_avx2(auVar22,2);
    dVar7 = dVar5 + *(sdword *)pauVar17[9] + (dVar7 ^ dVar12 ^ dVar6) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
    auVar22 = vpsrld_avx2(auVar22,0x1e);
    auVar18 = vpxor_avx2(auVar18,auVar20);
    dVar4 = dVar6 + *(sdword *)(pauVar17[9] + 4) + (dVar4 ^ dVar10 ^ dVar12) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
    dVar7 = dVar12 + *(sdword *)(pauVar17[9] + 8) + (dVar7 ^ dVar9 ^ dVar10) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    sVar1 = *(sdword *)(pauVar17[9] + 0xc);
    auVar21 = vpxor_avx2(auVar18,auVar22);
    auVar18 = vpaddd_avx2(auVar21,K_XMM_AR._0_32_);
    auVar18 = vmovdqu_avx(auVar18);
    pauVar16[4] = auVar18;
    dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
    dVar4 = dVar10 + sVar1 + (dVar4 ^ dVar11 ^ dVar9) + (dVar7 >> 0x1b | dVar7 * 0x20);
    auVar20 = vpalignr_avx2(auVar27,auVar28,8);
    auVar18 = vpsrldq_avx2(auVar21,4);
    dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
    dVar7 = dVar9 + *(sdword *)pauVar17[10] + (dVar7 & dVar5 | (dVar5 | dVar7) & dVar11) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    auVar20 = vpxor_avx2(auVar20,auVar25);
    auVar18 = vpxor_avx2(auVar18,auVar28);
    dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
    dVar4 = dVar11 + *(sdword *)(pauVar17[10] + 4) + (dVar4 & dVar6 | (dVar6 | dVar4) & dVar5) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    auVar20 = vpxor_avx2(auVar20,auVar18);
    auVar22 = vpslldq_avx2(auVar20,0xc);
    dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
    dVar7 = dVar5 + *(sdword *)(pauVar17[10] + 8) + (dVar7 & dVar12 | (dVar12 | dVar7) & dVar6) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    auVar18 = vpslld_avx2(auVar20,1);
    auVar20 = vpsrld_avx2(auVar20,0x1f);
    dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
    dVar4 = dVar6 + *(sdword *)(pauVar17[10] + 0xc) + (dVar4 & dVar10 | (dVar10 | dVar4) & dVar12) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    auVar18 = vpor_avx2(auVar18,auVar20);
    auVar20 = vpslld_avx2(auVar22,2);
    dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
    dVar7 = dVar12 + *(sdword *)pauVar17[0xb] + (dVar7 & dVar9 | (dVar9 | dVar7) & dVar10) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    auVar22 = vpsrld_avx2(auVar22,0x1e);
    auVar18 = vpxor_avx2(auVar18,auVar20);
    dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
    dVar4 = dVar10 + *(sdword *)(pauVar17[0xb] + 4) + (dVar4 & dVar11 | (dVar11 | dVar4) & dVar9) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
    dVar7 = dVar9 + *(sdword *)(pauVar17[0xb] + 8) + (dVar7 & dVar5 | (dVar5 | dVar7) & dVar11) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    sVar1 = *(sdword *)(pauVar17[0xb] + 0xc);
    auVar19 = vpxor_avx2(auVar18,auVar22);
    auVar18 = vpaddd_avx2(auVar19,K_XMM_AR._32_32_);
    auVar18 = vmovdqu_avx(auVar18);
    pauVar16[5] = auVar18;
    dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
    dVar4 = dVar11 + sVar1 + (dVar4 & dVar6 | (dVar6 | dVar4) & dVar5) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    auVar20 = vpalignr_avx2(auVar25,auVar27,8);
    auVar18 = vpsrldq_avx2(auVar19,4);
    dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
    dVar7 = dVar5 + *(sdword *)pauVar17[0xc] + (dVar7 & dVar12 | (dVar12 | dVar7) & dVar6) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    auVar20 = vpxor_avx2(auVar20,auVar21);
    auVar18 = vpxor_avx2(auVar18,auVar27);
    dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
    dVar4 = dVar6 + *(sdword *)(pauVar17[0xc] + 4) + (dVar4 & dVar10 | (dVar10 | dVar4) & dVar12) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    auVar20 = vpxor_avx2(auVar20,auVar18);
    auVar22 = vpslldq_avx2(auVar20,0xc);
    dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
    dVar7 = dVar12 + *(sdword *)(pauVar17[0xc] + 8) + (dVar7 & dVar9 | (dVar9 | dVar7) & dVar10) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    auVar18 = vpslld_avx2(auVar20,1);
    auVar20 = vpsrld_avx2(auVar20,0x1f);
    dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
    dVar4 = dVar10 + *(sdword *)(pauVar17[0xc] + 0xc) + (dVar4 & dVar11 | (dVar11 | dVar4) & dVar9)
            + (dVar7 >> 0x1b | dVar7 * 0x20);
    auVar18 = vpor_avx2(auVar18,auVar20);
    auVar20 = vpslld_avx2(auVar22,2);
    dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
    dVar7 = dVar9 + *(sdword *)pauVar17[0xd] + (dVar7 & dVar5 | (dVar5 | dVar7) & dVar11) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    auVar22 = vpsrld_avx2(auVar22,0x1e);
    auVar18 = vpxor_avx2(auVar18,auVar20);
    dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
    dVar4 = dVar11 + *(sdword *)(pauVar17[0xd] + 4) + (dVar4 & dVar6 | (dVar6 | dVar4) & dVar5) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
    dVar7 = dVar5 + *(sdword *)(pauVar17[0xd] + 8) + (dVar7 & dVar12 | (dVar12 | dVar7) & dVar6) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    sVar1 = *(sdword *)(pauVar17[0xd] + 0xc);
    auVar22 = vpxor_avx2(auVar18,auVar22);
    auVar18 = vpaddd_avx2(auVar22,K_XMM_AR._32_32_);
    auVar18 = vmovdqu_avx(auVar18);
    pauVar16[6] = auVar18;
    dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
    dVar4 = dVar6 + sVar1 + (dVar4 & dVar10 | (dVar10 | dVar4) & dVar12) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    auVar20 = vpalignr_avx2(auVar21,auVar25,8);
    auVar18 = vpsrldq_avx2(auVar22,4);
    dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
    dVar7 = dVar12 + *(sdword *)pauVar17[0xe] + (dVar7 & dVar9 | (dVar9 | dVar7) & dVar10) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    auVar20 = vpxor_avx2(auVar20,auVar19);
    auVar18 = vpxor_avx2(auVar18,auVar25);
    dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
    dVar4 = dVar10 + *(sdword *)(pauVar17[0xe] + 4) + (dVar4 & dVar11 | (dVar11 | dVar4) & dVar9) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    auVar20 = vpxor_avx2(auVar20,auVar18);
    auVar23 = vpslldq_avx2(auVar20,0xc);
    dVar10 = dVar4 >> 2 | dVar4 * 0x40000000;
    dVar7 = dVar9 + *(sdword *)(pauVar17[0xe] + 8) + (dVar7 & dVar5 | (dVar5 | dVar7) & dVar11) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar9 = dVar7 >> 2 | dVar7 * 0x40000000;
    auVar18 = vpslld_avx2(auVar20,1);
    auVar20 = vpsrld_avx2(auVar20,0x1f);
    dVar4 = dVar11 + *(sdword *)(pauVar17[0xe] + 0xc) + (dVar4 & dVar6 | (dVar6 | dVar4) & dVar5) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    in_stack_00000010 = (undefined1 *)((int)in_stack_00000010 + 0x80);
    if (pauVar8 <= in_stack_00000010) {
      in_stack_00000010 = K_XMM_AR;
    }
    dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar18 = vpor_avx2(auVar18,auVar20);
    auVar20 = vpslld_avx2(auVar23,2);
    dVar7 = dVar5 + *(sdword *)pauVar17[0xf] + (dVar7 ^ dVar10 ^ dVar6) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
    auVar23 = vpsrld_avx2(auVar23,0x1e);
    auVar18 = vpxor_avx2(auVar18,auVar20);
    dVar4 = dVar6 + *(sdword *)(pauVar17[0xf] + 4) + (dVar4 ^ dVar9 ^ dVar10) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
    dVar7 = dVar10 + *(sdword *)(pauVar17[0xf] + 8) + (dVar7 ^ dVar12 ^ dVar9) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    sVar1 = *(sdword *)(pauVar17[0xf] + 0xc);
    dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
    auVar20 = vpxor_avx2(auVar18,auVar23);
    auVar18 = vpaddd_avx2(auVar20,K_XMM_AR._32_32_);
    auVar18 = vmovdqu_avx(auVar18);
    pauVar16[7] = auVar18;
    dVar4 = dVar9 + sVar1 + (dVar4 ^ dVar11 ^ dVar12) + (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar13 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar18 = vpalignr_avx2(auVar20,auVar22,8);
    dVar7 = dVar12 + *(sdword *)pauVar17[0x10] + (dVar7 ^ dVar5 ^ dVar11) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
    auVar23 = vpxor_avx2(auVar29,auVar28);
    dVar4 = dVar11 + *(sdword *)(pauVar17[0x10] + 4) + (dVar4 ^ dVar6 ^ dVar5) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar18 = vpxor_avx2(auVar18,auVar21);
    dVar7 = dVar5 + *(sdword *)(pauVar17[0x10] + 8) + (dVar7 ^ dVar13 ^ dVar6) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
    auVar23 = vpxor_avx2(auVar23,auVar18);
    dVar4 = dVar6 + *(sdword *)(pauVar17[0x10] + 0xc) + (dVar4 ^ dVar10 ^ dVar13) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar18 = vpslld_avx2(auVar23,2);
    dVar7 = dVar13 + *(sdword *)pauVar17[0x11] + (dVar7 ^ dVar9 ^ dVar10) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
    auVar23 = vpsrld_avx2(auVar23,0x1e);
    auVar26 = vpor_avx2(auVar18,auVar23);
    dVar4 = dVar10 + *(sdword *)(pauVar17[0x11] + 4) + (dVar4 ^ dVar11 ^ dVar9) +
            (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar13 = dVar4 >> 2 | dVar4 * 0x40000000;
    dVar7 = dVar9 + *(sdword *)(pauVar17[0x11] + 8) + (dVar7 ^ dVar5 ^ dVar11) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    sVar1 = *(sdword *)(pauVar17[0x11] + 0xc);
    dVar12 = dVar7 >> 2 | dVar7 * 0x40000000;
    auVar18 = vpaddd_avx2(auVar26,K_XMM_AR._32_32_);
    auVar18 = vmovdqu_avx(auVar18);
    pauVar16[8] = auVar18;
    dVar4 = dVar11 + sVar1 + (dVar4 ^ dVar6 ^ dVar5) + (dVar7 >> 0x1b | dVar7 * 0x20);
    dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar18 = vpalignr_avx2(auVar26,auVar20,8);
    dVar11 = dVar5 + *(sdword *)pauVar17[0x12] + (dVar7 ^ dVar13 ^ dVar6) +
             (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar5 = dVar11 >> 2 | dVar11 * 0x40000000;
    auVar23 = vpxor_avx2(auVar28,auVar27);
    dVar4 = dVar6 + *(sdword *)(pauVar17[0x12] + 4) + (dVar4 ^ dVar12 ^ dVar13) +
            (dVar11 >> 0x1b | dVar11 * 0x20);
    dVar10 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar18 = vpxor_avx2(auVar18,auVar19);
    dVar6 = dVar13 + *(sdword *)(pauVar17[0x12] + 8) + (dVar11 ^ dVar9 ^ dVar12) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar7 = dVar6 >> 2 | dVar6 * 0x40000000;
    auVar23 = vpxor_avx2(auVar23,auVar18);
    dVar12 = dVar12 + *(sdword *)(pauVar17[0x12] + 0xc) + (dVar4 ^ dVar5 ^ dVar9) +
             (dVar6 >> 0x1b | dVar6 * 0x20);
    dVar11 = dVar12 >> 2 | dVar12 * 0x40000000;
    auVar18 = vpslld_avx2(auVar23,2);
    dVar4 = dVar9 + *(sdword *)pauVar17[0x13] + (dVar6 ^ dVar10 ^ dVar5) +
            (dVar12 >> 0x1b | dVar12 * 0x20);
    dVar6 = dVar4 >> 2 | dVar4 * 0x40000000;
    auVar23 = vpsrld_avx2(auVar23,0x1e);
    auVar23 = vpor_avx2(auVar18,auVar23);
    dVar9 = dVar5 + *(sdword *)(pauVar17[0x13] + 4) + (dVar12 ^ dVar7 ^ dVar10) +
            (dVar4 >> 0x1b | dVar4 * 0x20);
    dVar5 = dVar10 + *(sdword *)(pauVar17[0x13] + 8) + (dVar4 ^ dVar11 ^ dVar7) +
            (dVar9 >> 0x1b | dVar9 * 0x20);
    dVar4 = dVar9 ^ dVar6 ^ dVar11;
    sVar1 = *(sdword *)(pauVar17[0x13] + 0xc);
    auVar18 = vpaddd_avx2(auVar23,K_XMM_AR._32_32_);
    auVar18 = vmovdqu_avx(auVar18);
    pauVar16[9] = auVar18;
    dVar7 = dVar7 + sVar1 + dVar4 + (dVar5 >> 0x1b | dVar5 * 0x20) + *in_stack_00000008;
    *in_stack_00000008 = dVar7;
    dVar5 = dVar5 + in_stack_00000008[1];
    in_stack_00000008[1] = dVar5;
    dVar9 = (dVar9 >> 2 | dVar9 * 0x40000000) + in_stack_00000008[2];
    in_stack_00000008[2] = dVar9;
    dVar6 = dVar6 + in_stack_00000008[3];
    in_stack_00000008[3] = dVar6;
    dVar11 = dVar11 + in_stack_00000008[4];
    in_stack_00000008[4] = dVar11;
    pauVar3 = pauVar16;
    if (in_stack_00000010 != K_XMM_AR) {
      dVar10 = dVar5 >> 2 | dVar5 * 0x40000000;
      dVar12 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar18 = vpalignr_avx2(auVar23,auVar26,8);
      dVar11 = dVar11 + *(sdword *)(*pauVar17 + 0x10) + (dVar5 & dVar9 ^ ~dVar5 & dVar6) +
               (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar4 = dVar11 >> 2 | dVar11 * 0x40000000;
      auVar27 = vpxor_avx2(auVar27,auVar25);
      dVar6 = dVar6 + *(sdword *)(*pauVar17 + 0x14) + (dVar7 & dVar10 ^ ~dVar7 & dVar9) +
              (dVar11 >> 0x1b | dVar11 * 0x20);
      dVar14 = dVar6 >> 2 | dVar6 * 0x40000000;
      auVar18 = vpxor_avx2(auVar18,auVar22);
      dVar11 = dVar9 + *(sdword *)(*pauVar17 + 0x18) + (dVar11 & dVar12 ^ ~dVar11 & dVar10) +
               (dVar6 >> 0x1b | dVar6 * 0x20);
      dVar13 = dVar11 >> 2 | dVar11 * 0x40000000;
      auVar27 = vpxor_avx2(auVar27,auVar18);
      dVar6 = dVar10 + *(sdword *)(*pauVar17 + 0x1c) + (dVar6 & dVar4 ^ ~dVar6 & dVar12) +
              (dVar11 >> 0x1b | dVar11 * 0x20);
      dVar9 = dVar6 >> 2 | dVar6 * 0x40000000;
      auVar18 = vpslld_avx2(auVar27,2);
      dVar7 = dVar12 + *(sdword *)(pauVar17[1] + 0x10) + (dVar11 & dVar14 ^ ~dVar11 & dVar4) +
              (dVar6 >> 0x1b | dVar6 * 0x20);
      dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar27 = vpsrld_avx2(auVar27,0x1e);
      auVar27 = vpor_avx2(auVar18,auVar27);
      dVar4 = dVar4 + *(sdword *)(pauVar17[1] + 0x14) + (dVar6 & dVar13 ^ ~dVar6 & dVar14) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
      dVar7 = dVar14 + *(sdword *)(pauVar17[1] + 0x18) + (dVar7 & dVar9 ^ ~dVar7 & dVar13) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      sVar1 = *(sdword *)(pauVar17[1] + 0x1c);
      dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar18 = vpaddd_avx2(auVar27,K_XMM_AR._64_32_);
      auVar18 = vmovdqu_avx(auVar18);
      pauVar16[10] = auVar18;
      dVar4 = dVar13 + sVar1 + (dVar4 & dVar11 ^ ~dVar4 & dVar9) + (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
      auVar18 = vpalignr_avx2(auVar27,auVar23,8);
      dVar7 = dVar9 + *(sdword *)(pauVar17[2] + 0x10) + (dVar7 & dVar5 ^ ~dVar7 & dVar11) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar25 = vpxor_avx2(auVar25,auVar21);
      dVar4 = dVar11 + *(sdword *)(pauVar17[2] + 0x14) + (dVar4 & dVar6 ^ ~dVar4 & dVar5) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
      auVar18 = vpxor_avx2(auVar18,auVar20);
      dVar7 = dVar5 + *(sdword *)(pauVar17[2] + 0x18) + (dVar7 & dVar12 ^ ~dVar7 & dVar6) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar25 = vpxor_avx2(auVar25,auVar18);
      dVar4 = dVar6 + *(sdword *)(pauVar17[2] + 0x1c) + (dVar4 & dVar10 ^ ~dVar4 & dVar12) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
      auVar18 = vpslld_avx2(auVar25,2);
      dVar7 = dVar12 + *(sdword *)(pauVar17[3] + 0x10) + (dVar7 & dVar9 ^ ~dVar7 & dVar10) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar25 = vpsrld_avx2(auVar25,0x1e);
      auVar25 = vpor_avx2(auVar18,auVar25);
      dVar4 = dVar10 + *(sdword *)(pauVar17[3] + 0x14) + (dVar4 & dVar11 ^ ~dVar4 & dVar9) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
      dVar7 = dVar9 + *(sdword *)(pauVar17[3] + 0x18) + (dVar7 & dVar5 ^ ~dVar7 & dVar11) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      sVar1 = *(sdword *)(pauVar17[3] + 0x1c);
      dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar18 = vpaddd_avx2(auVar25,K_XMM_AR._64_32_);
      auVar18 = vmovdqu_avx(auVar18);
      pauVar16[0xb] = auVar18;
      dVar4 = dVar11 + sVar1 + (dVar4 & dVar6 ^ ~dVar4 & dVar5) + (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
      auVar18 = vpalignr_avx2(auVar25,auVar27,8);
      dVar7 = dVar5 + *(sdword *)(pauVar17[4] + 0x10) + (dVar7 & dVar12 ^ ~dVar7 & dVar6) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar21 = vpxor_avx2(auVar21,auVar19);
      dVar4 = dVar6 + *(sdword *)(pauVar17[4] + 0x14) + (dVar4 & dVar10 ^ ~dVar4 & dVar12) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
      auVar18 = vpxor_avx2(auVar18,auVar26);
      dVar7 = dVar12 + *(sdword *)(pauVar17[4] + 0x18) + (dVar7 & dVar9 ^ ~dVar7 & dVar10) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar21 = vpxor_avx2(auVar21,auVar18);
      dVar4 = dVar10 + *(sdword *)(pauVar17[4] + 0x1c) + (dVar4 & dVar11 ^ ~dVar4 & dVar9) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
      auVar18 = vpslld_avx2(auVar21,2);
      dVar7 = dVar9 + *(sdword *)(pauVar17[5] + 0x10) + (dVar7 ^ dVar5 ^ dVar11) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar21 = vpsrld_avx2(auVar21,0x1e);
      auVar21 = vpor_avx2(auVar18,auVar21);
      dVar4 = dVar11 + *(sdword *)(pauVar17[5] + 0x14) + (dVar4 ^ dVar6 ^ dVar5) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
      dVar7 = dVar5 + *(sdword *)(pauVar17[5] + 0x18) + (dVar7 ^ dVar12 ^ dVar6) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      sVar1 = *(sdword *)(pauVar17[5] + 0x1c);
      dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar18 = vpaddd_avx2(auVar21,K_XMM_AR._64_32_);
      auVar18 = vmovdqu_avx(auVar18);
      pauVar16[0xc] = auVar18;
      dVar4 = dVar6 + sVar1 + (dVar4 ^ dVar10 ^ dVar12) + (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
      auVar18 = vpalignr_avx2(auVar21,auVar25,8);
      dVar7 = dVar12 + *(sdword *)(pauVar17[6] + 0x10) + (dVar7 ^ dVar9 ^ dVar10) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar19 = vpxor_avx2(auVar19,auVar22);
      dVar4 = dVar10 + *(sdword *)(pauVar17[6] + 0x14) + (dVar4 ^ dVar11 ^ dVar9) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
      auVar18 = vpxor_avx2(auVar18,auVar23);
      dVar7 = dVar9 + *(sdword *)(pauVar17[6] + 0x18) + (dVar7 ^ dVar5 ^ dVar11) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar19 = vpxor_avx2(auVar19,auVar18);
      dVar4 = dVar11 + *(sdword *)(pauVar17[6] + 0x1c) + (dVar4 ^ dVar6 ^ dVar5) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
      auVar18 = vpslld_avx2(auVar19,2);
      dVar7 = dVar5 + *(sdword *)(pauVar17[7] + 0x10) + (dVar7 ^ dVar12 ^ dVar6) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar19 = vpsrld_avx2(auVar19,0x1e);
      auVar19 = vpor_avx2(auVar18,auVar19);
      dVar4 = dVar6 + *(sdword *)(pauVar17[7] + 0x14) + (dVar4 ^ dVar10 ^ dVar12) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
      dVar7 = dVar12 + *(sdword *)(pauVar17[7] + 0x18) + (dVar7 ^ dVar9 ^ dVar10) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      sVar1 = *(sdword *)(pauVar17[7] + 0x1c);
      dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar18 = vpaddd_avx2(auVar19,K_XMM_AR._64_32_);
      auVar18 = vmovdqu_avx(auVar18);
      pauVar16[0xd] = auVar18;
      dVar4 = dVar10 + sVar1 + (dVar4 ^ dVar11 ^ dVar9) + (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
      auVar18 = vpalignr_avx2(auVar19,auVar21,8);
      dVar7 = dVar9 + *(sdword *)(pauVar17[8] + 0x10) + (dVar7 ^ dVar5 ^ dVar11) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar22 = vpxor_avx2(auVar22,auVar20);
      dVar4 = dVar11 + *(sdword *)(pauVar17[8] + 0x14) + (dVar4 ^ dVar6 ^ dVar5) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
      auVar18 = vpxor_avx2(auVar18,auVar27);
      dVar7 = dVar5 + *(sdword *)(pauVar17[8] + 0x18) + (dVar7 ^ dVar12 ^ dVar6) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar22 = vpxor_avx2(auVar22,auVar18);
      dVar4 = dVar6 + *(sdword *)(pauVar17[8] + 0x1c) + (dVar4 ^ dVar10 ^ dVar12) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
      auVar18 = vpslld_avx2(auVar22,2);
      dVar7 = dVar12 + *(sdword *)(pauVar17[9] + 0x10) + (dVar7 ^ dVar9 ^ dVar10) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar22 = vpsrld_avx2(auVar22,0x1e);
      auVar22 = vpor_avx2(auVar18,auVar22);
      dVar4 = dVar10 + *(sdword *)(pauVar17[9] + 0x14) + (dVar4 ^ dVar11 ^ dVar9) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
      dVar7 = dVar9 + *(sdword *)(pauVar17[9] + 0x18) + (dVar7 ^ dVar5 ^ dVar11) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      sVar1 = *(sdword *)(pauVar17[9] + 0x1c);
      auVar18 = vpaddd_avx2(auVar22,K_XMM_AR._64_32_);
      auVar18 = vmovdqu_avx(auVar18);
      pauVar16[0xe] = auVar18;
      dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
      dVar4 = dVar11 + sVar1 + (dVar4 ^ dVar6 ^ dVar5) + (dVar7 >> 0x1b | dVar7 * 0x20);
      auVar18 = vpalignr_avx2(auVar22,auVar19,8);
      dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
      dVar7 = dVar5 + *(sdword *)(pauVar17[10] + 0x10) + (dVar7 & dVar12 | (dVar12 | dVar7) & dVar6)
              + (dVar4 >> 0x1b | dVar4 * 0x20);
      auVar20 = vpxor_avx2(auVar20,auVar26);
      dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
      dVar4 = dVar6 + *(sdword *)(pauVar17[10] + 0x14) +
              (dVar4 & dVar10 | (dVar10 | dVar4) & dVar12) + (dVar7 >> 0x1b | dVar7 * 0x20);
      auVar18 = vpxor_avx2(auVar18,auVar25);
      dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
      dVar7 = dVar12 + *(sdword *)(pauVar17[10] + 0x18) + (dVar7 & dVar9 | (dVar9 | dVar7) & dVar10)
              + (dVar4 >> 0x1b | dVar4 * 0x20);
      auVar20 = vpxor_avx2(auVar20,auVar18);
      dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
      dVar4 = dVar10 + *(sdword *)(pauVar17[10] + 0x1c) +
              (dVar4 & dVar11 | (dVar11 | dVar4) & dVar9) + (dVar7 >> 0x1b | dVar7 * 0x20);
      auVar18 = vpslld_avx2(auVar20,2);
      dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
      dVar7 = dVar9 + *(sdword *)(pauVar17[0xb] + 0x10) + (dVar7 & dVar5 | (dVar5 | dVar7) & dVar11)
              + (dVar4 >> 0x1b | dVar4 * 0x20);
      auVar20 = vpsrld_avx2(auVar20,0x1e);
      auVar20 = vpor_avx2(auVar18,auVar20);
      dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
      dVar4 = dVar11 + *(sdword *)(pauVar17[0xb] + 0x14) + (dVar4 & dVar6 | (dVar6 | dVar4) & dVar5)
              + (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
      dVar7 = dVar5 + *(sdword *)(pauVar17[0xb] + 0x18) +
              (dVar7 & dVar12 | (dVar12 | dVar7) & dVar6) + (dVar4 >> 0x1b | dVar4 * 0x20);
      sVar1 = *(sdword *)(pauVar17[0xb] + 0x1c);
      auVar18 = vpaddd_avx2(auVar20,K_XMM_AR._96_32_);
      auVar18 = vmovdqu_avx(auVar18);
      pauVar16[0xf] = auVar18;
      dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
      dVar4 = dVar6 + sVar1 + (dVar4 & dVar10 | (dVar10 | dVar4) & dVar12) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      auVar18 = vpalignr_avx2(auVar20,auVar22,8);
      dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
      dVar7 = dVar12 + *(sdword *)(pauVar17[0xc] + 0x10) +
              (dVar7 & dVar9 | (dVar9 | dVar7) & dVar10) + (dVar4 >> 0x1b | dVar4 * 0x20);
      auVar26 = vpxor_avx2(auVar26,auVar23);
      dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
      dVar4 = dVar10 + *(sdword *)(pauVar17[0xc] + 0x14) +
              (dVar4 & dVar11 | (dVar11 | dVar4) & dVar9) + (dVar7 >> 0x1b | dVar7 * 0x20);
      auVar18 = vpxor_avx2(auVar18,auVar21);
      dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
      dVar7 = dVar9 + *(sdword *)(pauVar17[0xc] + 0x18) + (dVar7 & dVar5 | (dVar5 | dVar7) & dVar11)
              + (dVar4 >> 0x1b | dVar4 * 0x20);
      auVar26 = vpxor_avx2(auVar26,auVar18);
      dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
      dVar4 = dVar11 + *(sdword *)(pauVar17[0xc] + 0x1c) + (dVar4 & dVar6 | (dVar6 | dVar4) & dVar5)
              + (dVar7 >> 0x1b | dVar7 * 0x20);
      auVar18 = vpslld_avx2(auVar26,2);
      dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
      dVar7 = dVar5 + *(sdword *)(pauVar17[0xd] + 0x10) +
              (dVar7 & dVar12 | (dVar12 | dVar7) & dVar6) + (dVar4 >> 0x1b | dVar4 * 0x20);
      auVar26 = vpsrld_avx2(auVar26,0x1e);
      auVar26 = vpor_avx2(auVar18,auVar26);
      dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
      dVar4 = dVar6 + *(sdword *)(pauVar17[0xd] + 0x14) +
              (dVar4 & dVar10 | (dVar10 | dVar4) & dVar12) + (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
      dVar7 = dVar12 + *(sdword *)(pauVar17[0xd] + 0x18) +
              (dVar7 & dVar9 | (dVar9 | dVar7) & dVar10) + (dVar4 >> 0x1b | dVar4 * 0x20);
      sVar1 = *(sdword *)(pauVar17[0xd] + 0x1c);
      auVar18 = vpaddd_avx2(auVar26,K_XMM_AR._96_32_);
      auVar18 = vmovdqu_avx(auVar18);
      pauVar16[0x10] = auVar18;
      dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
      dVar4 = dVar10 + sVar1 + (dVar4 & dVar11 | (dVar11 | dVar4) & dVar9) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      auVar18 = vpalignr_avx2(auVar26,auVar20,8);
      dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
      dVar7 = dVar9 + *(sdword *)(pauVar17[0xe] + 0x10) + (dVar7 & dVar5 | (dVar5 | dVar7) & dVar11)
              + (dVar4 >> 0x1b | dVar4 * 0x20);
      auVar23 = vpxor_avx2(auVar23,auVar27);
      dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
      dVar4 = dVar11 + *(sdword *)(pauVar17[0xe] + 0x14) + (dVar4 & dVar6 | (dVar6 | dVar4) & dVar5)
              + (dVar7 >> 0x1b | dVar7 * 0x20);
      auVar18 = vpxor_avx2(auVar18,auVar19);
      dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
      dVar7 = dVar5 + *(sdword *)(pauVar17[0xe] + 0x18) +
              (dVar7 & dVar12 | (dVar12 | dVar7) & dVar6) + (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar18 = vpxor_avx2(auVar23,auVar18);
      dVar4 = dVar6 + *(sdword *)(pauVar17[0xe] + 0x1c) +
              (dVar4 & dVar10 | (dVar10 | dVar4) & dVar12) + (dVar7 >> 0x1b | dVar7 * 0x20);
      puVar15 = (undefined1 *)((int)puVar15 + 0x80);
      if (pauVar8 <= puVar15) {
        in_stack_00000010 = K_XMM_AR;
      }
      dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
      auVar19 = vpslld_avx2(auVar18,2);
      dVar7 = dVar12 + *(sdword *)(pauVar17[0xf] + 0x10) + (dVar7 ^ dVar9 ^ dVar10) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar18 = vpsrld_avx2(auVar18,0x1e);
      auVar23 = vpor_avx2(auVar19,auVar18);
      dVar4 = dVar10 + *(sdword *)(pauVar17[0xf] + 0x14) + (dVar4 ^ dVar11 ^ dVar9) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
      dVar7 = dVar9 + *(sdword *)(pauVar17[0xf] + 0x18) + (dVar7 ^ dVar5 ^ dVar11) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      sVar1 = *(sdword *)(pauVar17[0xf] + 0x1c);
      dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar18 = vpaddd_avx2(auVar23,K_XMM_AR._96_32_);
      auVar18 = vmovdqu_avx(auVar18);
      pauVar16[0x11] = auVar18;
      dVar4 = dVar11 + sVar1 + (dVar4 ^ dVar6 ^ dVar5) + (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
      auVar18 = vpalignr_avx2(auVar23,auVar26,8);
      dVar7 = dVar5 + *(sdword *)(pauVar17[0x10] + 0x10) + (dVar7 ^ dVar12 ^ dVar6) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar19 = vpxor_avx2(auVar27,auVar25);
      dVar4 = dVar6 + *(sdword *)(pauVar17[0x10] + 0x14) + (dVar4 ^ dVar10 ^ dVar12) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
      auVar18 = vpxor_avx2(auVar18,auVar22);
      dVar7 = dVar12 + *(sdword *)(pauVar17[0x10] + 0x18) + (dVar7 ^ dVar9 ^ dVar10) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar22 = vpxor_avx2(auVar19,auVar18);
      dVar4 = dVar10 + *(sdword *)(pauVar17[0x10] + 0x1c) + (dVar4 ^ dVar11 ^ dVar9) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar13 = dVar4 >> 2 | dVar4 * 0x40000000;
      auVar18 = vpslld_avx2(auVar22,2);
      dVar7 = dVar9 + *(sdword *)(pauVar17[0x11] + 0x10) + (dVar7 ^ dVar5 ^ dVar11) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar12 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar22 = vpsrld_avx2(auVar22,0x1e);
      auVar22 = vpor_avx2(auVar18,auVar22);
      dVar4 = dVar11 + *(sdword *)(pauVar17[0x11] + 0x14) + (dVar4 ^ dVar6 ^ dVar5) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar10 = dVar4 >> 2 | dVar4 * 0x40000000;
      dVar7 = dVar5 + *(sdword *)(pauVar17[0x11] + 0x18) + (dVar7 ^ dVar13 ^ dVar6) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      sVar1 = *(sdword *)(pauVar17[0x11] + 0x1c);
      dVar11 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar18 = vpaddd_avx2(auVar22,K_XMM_AR._96_32_);
      auVar18 = vmovdqu_avx(auVar18);
      pauVar16[0x12] = auVar18;
      dVar4 = dVar6 + sVar1 + (dVar4 ^ dVar12 ^ dVar13) + (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar9 = dVar4 >> 2 | dVar4 * 0x40000000;
      auVar18 = vpalignr_avx2(auVar22,auVar23,8);
      dVar7 = dVar13 + *(sdword *)(pauVar17[0x12] + 0x10) + (dVar7 ^ dVar10 ^ dVar12) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar6 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar22 = vpxor_avx2(auVar25,auVar21);
      dVar4 = dVar12 + *(sdword *)(pauVar17[0x12] + 0x14) + (dVar4 ^ dVar11 ^ dVar10) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar12 = dVar4 >> 2 | dVar4 * 0x40000000;
      auVar18 = vpxor_avx2(auVar18,auVar20);
      dVar7 = dVar10 + *(sdword *)(pauVar17[0x12] + 0x18) + (dVar7 ^ dVar9 ^ dVar11) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar10 = dVar7 >> 2 | dVar7 * 0x40000000;
      auVar20 = vpxor_avx2(auVar22,auVar18);
      dVar4 = dVar11 + *(sdword *)(pauVar17[0x12] + 0x1c) + (dVar4 ^ dVar6 ^ dVar9) +
              (dVar7 >> 0x1b | dVar7 * 0x20);
      dVar5 = dVar4 >> 2 | dVar4 * 0x40000000;
      auVar18 = vpslld_avx2(auVar20,2);
      dVar9 = dVar9 + *(sdword *)(pauVar17[0x13] + 0x10) + (dVar7 ^ dVar12 ^ dVar6) +
              (dVar4 >> 0x1b | dVar4 * 0x20);
      dVar7 = dVar9 >> 2 | dVar9 * 0x40000000;
      auVar20 = vpsrld_avx2(auVar20,0x1e);
      auVar18 = vpor_avx2(auVar18,auVar20);
      dVar11 = dVar6 + *(sdword *)(pauVar17[0x13] + 0x14) + (dVar4 ^ dVar10 ^ dVar12) +
               (dVar9 >> 0x1b | dVar9 * 0x20);
      dVar6 = dVar12 + *(sdword *)(pauVar17[0x13] + 0x18) + (dVar9 ^ dVar5 ^ dVar10) +
              (dVar11 >> 0x1b | dVar11 * 0x20);
      sVar1 = *(sdword *)(pauVar17[0x13] + 0x1c);
      auVar18 = vpaddd_avx2(auVar18,K_XMM_AR._96_32_);
      auVar18 = vmovdqu_avx(auVar18);
      pauVar16[0x13] = auVar18;
      dVar4 = dVar10 + sVar1 + (dVar11 ^ dVar7 ^ dVar5) + (dVar6 >> 0x1b | dVar6 * 0x20) +
              *in_stack_00000008;
      *in_stack_00000008 = dVar4;
      dVar6 = dVar6 + in_stack_00000008[1];
      in_stack_00000008[1] = dVar6;
      dVar11 = (dVar11 >> 2 | dVar11 * 0x40000000) + in_stack_00000008[2];
      in_stack_00000008[2] = dVar11;
      dVar7 = dVar7 + in_stack_00000008[3];
      in_stack_00000008[3] = dVar7;
      dVar5 = dVar5 + in_stack_00000008[4];
      in_stack_00000008[4] = dVar5;
      pauVar3 = pauVar17;
      pauVar17 = pauVar16;
    }
  }
  return;
}



void type__eq_crypto_sha1_digest(crypto_sha1_digest *p,crypto_sha1_digest *q,bool r)

{
  int unaff_R14;
  
  while (&stack0x00000000 <= *(undefined **)(unaff_R14 + 0x10)) {
    runtime_morestack_noctxt();
  }
  if ((q->nx == p->nx) && (q->len == p->len)) {
    runtime_memequal();
  }
  return;
}



void crypto_x509___CertPool__Clone(crypto_x509_CertPool *s,crypto_x509_CertPool *~r0)

{
  runtime_hmap *len;
  runtime_hmap *extraout_RAX;
  runtime_hmap *extraout_RAX_00;
  runtime_hmap *extraout_RAX_01;
  runtime_hmap **extraout_RAX_02;
  crypto_x509_CertPool *p;
  runtime_hmap **extraout_RAX_03;
  runtime_hmap **extraout_RAX_04;
  void **ppvVar1;
  void *__dest;
  void **extraout_RAX_05;
  void **extraout_RAX_06;
  undefined *extraout_RAX_07;
  int iVar2;
  void *~r0_00;
  runtime_hmap *h;
  runtime_hmap *h_00;
  runtime_hmap *in_RDI;
  void *~r0_01;
  runtime_hmap *~r0_02;
  void *extraout_RDI;
  void *extraout_RDI_00;
  void *pvVar3;
  runtime_hmap *extraout_RDI_01;
  runtime_hmap **extraout_R11;
  runtime_hmap **extraout_R11_00;
  void **extraout_R11_01;
  int unaff_R14;
  crypto_x509_CertPool *pcStack0000000000000008;
  string in_stack_fffffffffffffea0;
  undefined4 local_114;
  undefined4 uStack_110;
  undefined4 uStack_10c;
  undefined4 uStack_108;
  undefined4 uStack_104;
  undefined4 uStack_100;
  undefined4 uStack_fc;
  void *local_f8;
  runtime_hmap **local_f0;
  void *local_e8;
  runtime_hmap *local_e0;
  runtime_hmap *local_d8;
  runtime_hmap *local_d0;
  runtime_hiter local_c8;
  runtime_hiter local_68;
  
  pcStack0000000000000008 = s;
  while (&local_e0 <= *(runtime_hmap ***)(unaff_R14 + 0x10)) {
    runtime_morestack_noctxt();
    in_RDI = extraout_RDI_01;
  }
  if (pcStack0000000000000008->byName == (map_string___int)0x0) {
    iVar2 = 0;
  }
  else {
    iVar2 = pcStack0000000000000008->byName->count;
  }
  runtime_makemap((internal_abi_MapType *)&DAT_0082dc40,iVar2,(runtime_hmap *)0x0,in_RDI);
  len = (runtime_hmap *)(pcStack0000000000000008->lazyCerts).len;
  local_d0 = extraout_RAX;
  runtime_makeslice((internal_abi_Type *)&DAT_00854d40,(int)len,(int)len,~r0_01);
  if (pcStack0000000000000008->haveSum == (map_crypto_x509_sum224_bool)0x0) {
    iVar2 = 0;
  }
  else {
    iVar2 = pcStack0000000000000008->haveSum->count;
  }
  local_d8 = extraout_RAX_00;
  runtime_makemap((internal_abi_MapType *)&DAT_0082dbe0,iVar2,(runtime_hmap *)0x0,~r0_02);
  local_e0 = extraout_RAX_01;
  runtime_newobject((internal_abi_Type *)&DAT_008780e0,~r0_00);
  local_f0 = extraout_RAX_02;
  if (runtime_writeBarrier._0_4_ != 0) {
    runtime_gcWriteBarrier1();
    *extraout_R11 = local_d0;
    local_f0 = extraout_RAX_03;
  }
  *local_f0 = local_d0;
  local_f0[2] = len;
  local_f0[3] = len;
  if (runtime_writeBarrier._0_4_ != 0) {
    runtime_gcWriteBarrier2();
    *extraout_R11_00 = local_d8;
    extraout_R11_00[1] = local_e0;
    local_f0 = extraout_RAX_04;
  }
  local_f0[1] = local_d8;
  local_f0[4] = local_e0;
  *(bool *)(local_f0 + 5) = pcStack0000000000000008->systemPool;
  FUN_0046cdab();
  runtime_mapiterinit((internal_abi_MapType *)&DAT_0082dc40,h,&local_68);
  while ((void **)local_68.key != (void **)0x0) {
                    // WARNING: Load size is inaccurate
    local_e8 = *local_68.key;
    pvVar3 = *(void **)((int)local_68.elem + 8);
                    // WARNING: Load size is inaccurate
    local_f8 = *local_68.elem;
    runtime_mallocgc((int)pvVar3 << 3,(internal_abi_Type *)0x0,false,local_f8);
    local_d8 = (runtime_hmap *)__dest;
    runtime_memmove(__dest,local_f8,(int)pvVar3 << 3);
    runtime_mapassign_faststr
              ((internal_abi_MapType *)&DAT_0082dc40,*local_f0,in_stack_fffffffffffffea0,local_e8);
    extraout_RAX_05[1] = pvVar3;
    extraout_RAX_05[2] = pvVar3;
    ppvVar1 = extraout_RAX_05;
    if (runtime_writeBarrier._0_4_ != 0) {
      runtime_gcWriteBarrier2();
      *extraout_R11_01 = local_d8;
      extraout_R11_01[1] = *extraout_RAX_06;
      ppvVar1 = extraout_RAX_06;
    }
    *ppvVar1 = local_d8;
    runtime_mapiternext(&local_68);
  }
  FUN_0046cdab();
  runtime_mapiterinit((internal_abi_MapType *)&DAT_0082dbe0,h_00,&local_c8);
  pvVar3 = extraout_RDI;
  while ((undefined4 *)local_c8.key != (undefined4 *)0x0) {
                    // WARNING: Load size is inaccurate
    local_114 = *local_c8.key;
    uStack_110 = *(undefined4 *)((int)local_c8.key + 4);
    uStack_10c = *(undefined4 *)((int)local_c8.key + 8);
    uStack_108 = *(undefined4 *)((int)local_c8.key + 0xc);
    uStack_104 = *(undefined4 *)((int)local_c8.key + 0x10);
    uStack_100 = *(undefined4 *)((int)local_c8.key + 0x14);
    uStack_fc = *(undefined4 *)((int)local_c8.key + 0x18);
    runtime_mapassign((internal_abi_MapType *)&DAT_0082dbe0,local_f0[4],&local_114,pvVar3);
    *extraout_RAX_07 = 1;
    runtime_mapiternext(&local_c8);
    pvVar3 = extraout_RDI_00;
  }
  runtime_typedslicecopy
            ((internal_abi_Type *)&DAT_00854d40,local_f0[1],(int)local_f0[2],
             (pcStack0000000000000008->lazyCerts).array,(pcStack0000000000000008->lazyCerts).len,
             (int)pcStack0000000000000008);
  return;
}



void crypto_x509___CertPool__findPotentialParents
               (crypto_x509_CertPool *s,crypto_x509_Certificate *cert,___crypto_x509_Certificate ~r0
               )

{
  uint uVar1;
  func_____crypto_x509_Certificate__error_ *pfVar2;
  runtime_slice ~r0_00;
  runtime_slice ~r0_01;
  runtime_slice ~r0_02;
  runtime_slice ~r0_03;
  runtime_slice ~r0_04;
  runtime_slice ~r0_05;
  undefined extraout_AL;
  int *extraout_RAX;
  crypto_x509_Certificate *candidate;
  void *extraout_RAX_00;
  int extraout_RAX_01;
  void *extraout_RAX_02;
  int extraout_RAX_03;
  void *extraout_RAX_04;
  int extraout_RAX_05;
  void *oldPtr;
  void *extraout_RAX_06;
  void *extraout_RAX_07;
  void *extraout_RAX_08;
  bool kidMatch;
  error *peVar3;
  error *peVar4;
  error *extraout_RCX;
  error *extraout_RCX_00;
  uint extraout_RCX_01;
  uint extraout_RCX_02;
  uint extraout_RCX_03;
  uint extraout_RCX_04;
  uint oldCap;
  error *extraout_RCX_05;
  error *extraout_RCX_06;
  error *extraout_RCX_07;
  int c;
  void *pvVar5;
  int found;
  error *extraout_RBX;
  error *extraout_RBX_00;
  uint num;
  uint extraout_RBX_01;
